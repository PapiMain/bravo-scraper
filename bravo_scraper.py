from dotenv import load_dotenv
import os
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException
from selenium.common.exceptions import TimeoutException
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
import time
import pytz
from tabulate import tabulate
import traceback
import sys
import json
from google.oauth2.service_account import Credentials
# from collections import defaultdict

# Load .env file
load_dotenv(".env")

# Read credentials
USER1_EMAIL = os.getenv("USER1_EMAIL")
USER1_PASSWORD = os.getenv("USER1_PASSWORD")
USER2_EMAIL = os.getenv("USER2_EMAIL")
USER2_PASSWORD = os.getenv("USER2_PASSWORD")

def create_driver():
    options = Options()
    
    # Headless with modern implementation
    options.add_argument("--headless=new")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    # Stealth flags
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--disable-infobars")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)

    # Realistic user-agent
    options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
    )

    driver = webdriver.Chrome(options=options)

    # Extra stealth tweak (removes navigator.webdriver)
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": """
        Object.defineProperty(navigator, 'webdriver', {
          get: () => undefined
        })
        """
    })

    return driver


def login_and_navigate(driver, username, password):
    print(f"ğŸ” Logging in as {username}")
    driver.get("https://kb.israelinfo.co.il")
    driver.execute_script("window.location.hash = '#login';")


    try:
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.NAME, "login")))
        time.sleep(2)
        driver.find_element(By.NAME, "login").send_keys(username)
        driver.find_element(By.NAME, "password").send_keys(password)
        driver.find_element(By.CSS_SELECTOR, "button.btn.btn-primary").click()

        # Wait for redirect
        WebDriverWait(driver, 30).until(lambda d: "kupatbarzel.co.il" in d.current_url)
        redirected_url = driver.current_url
        print(f"ğŸŒ Redirected to: {redirected_url}")

        # Build target URL
        if "index.cgi" in redirected_url:
            base_url = redirected_url.split("index.cgi")[0]
        else:
            base_url = redirected_url

        target_url = f"{base_url}index.cgi#!/kassy/shows"
        print(f"ğŸš€ Navigating to Bravo Shows page: {target_url}")
        driver.get(target_url)

        WebDriverWait(driver, 15).until(
            EC.frame_to_be_available_and_switch_to_it((By.ID, "frmKassa"))
        )

        return extract_main_table_data(driver)

    except TimeoutException:
        screenshot_path = f"login_failed_{username.replace('@', '_at_')}.png"
        driver.save_screenshot(screenshot_path)
        print(f"âŒ Timeout for user {username}. Screenshot saved to {screenshot_path}")
        raise



def extract_main_table_data(driver):
    print("ğŸ“„ Extracting main show table rows...")
    shows = []

    WebDriverWait(driver, 10).until(
        EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'tr[role="row"]'))
    )
    rows = driver.find_elements(By.CSS_SELECTOR, 'tr[role="row"]')

    for row in rows:
        try:
            if row.find_elements(By.TAG_NAME, "th"):
                print("â„¹ï¸ Skipping header row.")
                continue

            name = row.find_element(By.CSS_SELECTOR, 'td[data-title="×©× ×”×”×•×¤×¢×”"] a').text.strip()

            # âœ… This is the correct "×¢×¨×™×›×ª ×”××•×¢×“×™×" link
            details_link = row.find_element(By.XPATH, './/a[contains(@href, "?Tab=details")]').get_attribute("href")
            # âœ… Prevent double-prefixing:
            if details_link.startswith("http"):
                full_link = details_link
            else:
                full_link = "https://68.kupatbarzel.co.il" + details_link

            shows.append({
                "name": name,
                "link": full_link
            })

        except Exception as e:
            print("âš ï¸ Skipped a row:", e)
            print("ğŸ” HTML of skipped row:", row.get_attribute("outerHTML"))

    return shows

def extract_seances(driver, show_url, show_name):
    print(f"ğŸŒ Opening seance page: {show_url}")
    driver.get(show_url)
    time.sleep(2)

    try:
        WebDriverWait(driver, 5).until(
            EC.frame_to_be_available_and_switch_to_it((By.ID, "frmKassa"))
        )
    except:
        print("âš ï¸ No iframe found on seance page. Trying without it.")

    seances = []
    skipped_missing_field = 0
    skipped_other_errors = 0

    rows = driver.find_elements(By.CSS_SELECTOR, "tbody tr")

    for row in rows:
        try:
            cells = row.find_elements(By.TAG_NAME, "td")
            if not cells:
                continue

            city = row.find_element(By.CSS_SELECTOR, 'td[data-title="×¢×™×¨"]').text.strip()
            org = "×‘×¨××‘×•" 
            producer = row.find_element(By.CSS_SELECTOR, 'td[data-title="××¤×™×§"]').text.strip() 
            hall = row.find_element(By.CSS_SELECTOR, 'td[data-title="××•×œ×"]').text.strip()
            raw_date = row.find_element(By.CSS_SELECTOR, 'td[data-title="×ª××¨×™×š"]').text.strip()
            date = raw_date.replace(".", "/")
            time_ = row.find_element(By.CSS_SELECTOR, 'td[data-title="×©×¢×”"]').text.strip()
            sold = row.find_element(By.CSS_SELECTOR, 'td[data-title="× ××›×¨"]').text.strip()
            available = row.find_element(By.CSS_SELECTOR, 'td[data-title="× ×©××¨ ×œ××›×™×¨×”"]').text.strip()

            seances.append({
                "×”×¤×§×”": show_name,
                "×¢×™×¨": city,
                "××¨×’×•×Ÿ": org,        # this is now the correct "×‘×¨××‘×•"
                "××¤×™×§": producer,     # optional for later
                "××•×œ×": hall,
                "×ª××¨×™×š": date,
                "×©×¢×”": time_,
                "× ××›×¨×•": sold,
                "× ×©××¨ ×œ××›×™×¨×”": available,  # optional, not used in update for now
            })

        except NoSuchElementException:
            skipped_missing_field += 1
        except Exception as e:
            skipped_other_errors += 1
            # Optional: print(f"âš ï¸ Skipped a seance row due to unexpected error: {e}")

    if skipped_missing_field > 0:
        print(f"âš ï¸ Skipped {skipped_missing_field} seance rows due to missing required fields.")
    if skipped_other_errors > 0:
        print(f"âš ï¸ Skipped {skipped_other_errors} seance rows due to unexpected errors.")

    # âœ… Duplicate (name+date) detection
    seen = set()
    duplicates = []

    for s in seances:
        key = (s["×”×¤×§×”"], s["×ª××¨×™×š"])
        if key in seen:
            duplicates.append(key)
        else:
            seen.add(key)

    if duplicates:
        print("âš ï¸ Found duplicate seances with the same name and date:")
        for name, date in set(duplicates):
            print(f"   â€¢ {name} on {date}")

    try:
        driver.switch_to.default_content()
    except:
        pass

    return seances

def run_for_user(username, password):
    driver = create_driver()
    all_data = []

    try:
        shows = login_and_navigate(driver, username, password)

        for show in shows:
            print(f"\nğŸ“Œ {show['name']}")
            seances = extract_seances(driver, show["link"], show["name"])
            all_data.extend(seances)

    finally:
        driver.quit()

    return all_data

# Get the Google Sheets worksheet
def get_worksheet(sheet_name: str, tab_name: str):
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]

# ğŸŸ¢ Load JSON from env var, not file
    json_creds = os.environ["GOOGLE_CREDS_JSON"]
    service_account_info = json.loads(json_creds)
    service_account_info["private_key"] = service_account_info["private_key"].replace("\\n", "\n")

    creds = Credentials.from_service_account_info(service_account_info, scopes=scope)
    client = gspread.authorize(creds)
    sheet = client.open(sheet_name)
    return sheet.worksheet(tab_name)


def update_sheet_with_bravo_data(sheet, scraped_data):
    print("ğŸ“¥ Updating Google Sheet with scraped Bravo data...")

    records = sheet.get_all_records()
    headers = sheet.row_values(1)
    
    # Uncomment to see the first few rows of the sheet (debugging)
    # print("ğŸ“„ First few sheet rows:")
    # for row in records[:5]:
    #     print(f"   â€¢ {row['×”×¤×§×”']} | {row['×ª××¨×™×š']} | {row['××¨×’×•×Ÿ']}")


    # âœ… Make sure header names match your sheet exactly
    name_col = headers.index("×”×¤×§×”")
    date_col = headers.index("×ª××¨×™×š")
    org_col = headers.index("××¨×’×•×Ÿ")
    sold_col = headers.index("× ××›×¨×•")
    updated_col = headers.index("×¢×•×“×›×Ÿ ×œ××—×¨×•× ×”")

    updated_rows = 0
    not_found = []


    for seance in scraped_data:
        # Uncomment to see each seance being checked (debugging)
        # print(f"ğŸ” Checking seance: {seance['×”×¤×§×”']} | {seance['×ª××¨×™×š']} | {seance['××¨×’×•×Ÿ']}")
        if seance["××¨×’×•×Ÿ"] != "×‘×¨××‘×•":
            continue  # âœ… Skip non-Bravo entries
            
        israel_tz = pytz.timezone("Asia/Jerusalem")
        now_israel = datetime.now(israel_tz).strftime('%d/%m/%Y %H:%M:%S')
        
        found = False
        for i, row in enumerate(records):
            title_match = (seance["×”×¤×§×”"].strip() in row["×”×¤×§×”"].strip()
                or row["×”×¤×§×”"].strip() in seance["×”×¤×§×”"].strip())
            if (
                title_match
                and row["×ª××¨×™×š"].strip() == seance["×ª××¨×™×š"].strip()
                and row["××¨×’×•×Ÿ"].strip() in seance["××¨×’×•×Ÿ"].strip()
            ):
                sheet.update_cell(i + 2, sold_col + 1, seance["× ××›×¨×•"])
                sheet.update_cell(i + 2, updated_col + 1, now_israel)
                updated_rows += 1
                print(f"âœ… Row {i + 2} updated for '{seance['×”×¤×§×”']}' ×‘×ª××¨×™×š {seance['×ª××¨×™×š']}")
                found = True
                break

        if not found:
            not_found.append((seance["×”×¤×§×”"], seance["×ª××¨×™×š"]))

    print(f"\nâœ… Total updated rows: {updated_rows}")
    if not_found:
        print("âš ï¸ These Bravo seances were not found in the sheet:")
        for name, date in not_found:
            print(f"   â€¢ {name} ×‘×ª××¨×™×š {date}")


# Main execution
if __name__ == "__main__":
    try:
        combined_data = []

        combined_data += run_for_user(USER2_EMAIL, USER2_PASSWORD)
        combined_data += run_for_user(USER1_EMAIL, USER1_PASSWORD)

        print("\nğŸ“Š ×›×œ ×”××•×¤×¢×™× ××©× ×™ ×”××©×ª××©×™×:\n")

        if combined_data:
            # âœ… Remove duplicates (same name + date), keep first
            unique_data = []
            seen = set()
            duplicate_keys = []

            for s in combined_data:
                key = (s["×”×¤×§×”"], s["×ª××¨×™×š"])
                if key not in seen:
                    seen.add(key)
                    unique_data.append(s)
                else:
                    duplicate_keys.append(key)

            removed_count = len(combined_data) - len(unique_data)
            if duplicate_keys:
                print(f"âš ï¸ ×”×•×¡×¨×• {len(duplicate_keys)} ×©×•×¨×•×ª ×›×¤×•×œ×•×ª ×¢× ×©× ×•×ª××¨×™×š ×–×”×™×:")
                for name, date in set(duplicate_keys):
                    print(f"   â€¢ {name} ×‘×ª××¨×™×š {date}")
                print()

            # ğŸ§¾ Print table with only unique seances
            headers = unique_data[0].keys()
            rows = [row.values() for row in unique_data]
            print(tabulate(rows, headers=headers, tablefmt="grid", stralign="center"))

            # âœ… Update Google Sheet
            worksheet = get_worksheet("×“××˜×” ××¤×©×™×˜ ××•×¤×™×¡", "×›×¨×˜×™×¡×™×")
            update_sheet_with_bravo_data(worksheet, unique_data)
        else:
            print("âŒ ×œ× × ××¦××• ××•×¤×¢×™×.")
    
    except Exception as e:
        print("âŒ ERROR encountered:")
        traceback.print_exc()
        sys.exit(1)
